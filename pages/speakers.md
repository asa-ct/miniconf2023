---
layout: page-fullwidth
title: "Speakers & Presentations"
header: no
permalink: /speakers/
---

<div id="speaker1" style="display: flex; flex-direction: column;">

<h3>The Use of Real-World Evidence (RWE) in Health Technology Assessment (HTA) -- Opportunities and Challenges; 
[<a href="../docs/slides/AM1-SreeramRamagopalan.pdf">Slides</a>], 
[<a href="https://youtu.be/EFsl0mUbPIc" target="_blank">Recording</a>]
</h3>

<h4>Sreeram (Ram) Ramagopalan </h4>

<p>
<img class="imgfloat" src="../docs/ram.PNG"/>
Sreeram (Ram) Ramagopalan is currently a Research Fellow at the London School of Economics and Political Science. He has previously led Real World Evidence teams at Roche and Bristol Myers Squibb, focused on leveraging real-world evidence for Health Technology Assessment (HTA) to enable reimbursement of medicines. Ram holds a PhD in Epidemiology from the University of Oxford, as well as an MSc in Epidemiology from the London School of Hygiene and Tropical Medicine. He is an international expert in real world evidence with over 300 peer reviewed publications.

</p>


<h4>Abstract</h4>

Health Technology Assessment (HTA) is used as a tool to support evidence-based decision-making and to ensure scarce resources are efficiently spent. Real-world evidence (RWE) is used for different purposes in HTA, most importantly to estimate prevalence and/or incidence or to extrapolate short-term effectiveness beyond trial duration, but also to evaluate safety, resource use, costs or quality of life. Additionally, RWE is used to evaluate comparative effectiveness of MDs to support HTA. Observational studies of comparative effectiveness are, however, prone to several types of bias (e.g., selection bias, information bias, recall bias, and detection bias). For example, when observational studies fail to take into account confounding and effect modifying variables in the design or analysis, this may result in biased estimates of the effectiveness and cost-effectiveness of alternative health care interventions, which may lead to spending scarce resources sub-optimally. As a result, HTA agencies are reluctant to accept RWE as a measure of treatment effectiveness. This talk aims to cover methods development to address issues of bias and confounding for the wider acceptance of RWE by HTA agencies.  

</div>

----

<div id="speaker2" style="display: flex; flex-direction: column;">

<h3>Introduction to Real-World Evidence and Artificial Intelligence in Healthcare and Drug Development; 
[<a href="../docs/slides/AM2-YahuiTian.pdf">Slides</a>], 
[<a href="https://youtu.be/-5Qz8XppdnI" target="_blank">Recording</a>]
</h3>

<h4>Yahui Tian</h4>

<p>
<img class="imgfloat" src="../docs/Yahui.jpeg"/>
Dr. Yahui Tian is currently working as a principal statistician and real-world evidence statistics advisor in the department of Biostatistics and Data Sciences in Boehringer Ingelheim. Dr. Tian gets her Ph.D. degree in Statistics from University of Texas at Dallas. Her current work mainly focus on innovative workstreams that leverage real-world data and advanced analytics (e.g., data mining and machine learning) to facilitate clinical drug development and other advancements in the life cycle of drug development.
</p>


<h4>Abstract</h4>

There has been an increasing interest in using real-world evidence (RWE) to support healthcare decision-making, drug development and regulatory submission in recent years. RWE provides useful insights to disease understanding, comparative effectiveness, treatment safety, data-driven clinical trial design and health economics. However, due to the high dimensionality, heterogeneity and sometimes sparsity of real-world data (RWD),  representation and modeling is challenging. Artificial intelligence (AI) is capable of handling these difficulties and extracting meaningful patterns from complex structured and unstructured data. AI includes a collection of machine learning and deep learning algorithms which have shown promising value and impressive results across a variety of disease areas. This presentation introduces general concepts and regulatory guidelines of RWE and AI in healthcare and drug development, detailed use cases are discussed to demonstrate design process and contribution to medical discovery. RWE and AI are transforming the way decisions are made in healthcare, facilitating evidence generation in the value chain of medical research and drug development.

</div>



----

<div id="speaker3" style="display: flex; flex-direction: column;">

<h3>Enriching Real-World Data Based Study by Conducting Linkage among Multiple Data Sources; 
[<a href="../docs/slides/AM3-TianyuSun.pdf">Slides</a>], 
[<a href="https://youtu.be/WVOJNiGtV1M" target="_blank">Recording</a>]
</h3>

<h4>Tianyu Sun</h4>

<p>
<img class="imgfloat" src="../docs/Tianyu.jpg"/>
Dr. Tianyu Sun is Manger, Real-World Evidence & Analytics, Biostatistics and Programming at Moderna. He is partnering with cross-functional groups to support the development and execution of Real-World Data (RWD) based studies to enable disease insights and to enhance clinical development. Prior to joining Moderna, Tianyu had experience of different RWD sources, such as Medicare fee-for-service, Optum, RI Medicaid, etc. He also had previously been working as SAS programmer for clinical trial data analysis. Full list of publications: 
<a href="https://scholar.google.com/citations?user=fB8A030AAAAJ&hl=en&oi=sra" target="_blank">link</a>; 
ORCID: <a href="https://orcid.org/0000-0002-3996-1381" target="_blank">link</a>.
</p>


<h4>Abstract</h4>

The real-world data (RWD), such as claims and electronic health records (EHRs), has been widely used for observational studies to generate real-world evidence (RWE) of effectiveness and safety profile for treatments and interventions. However, each data source by themselves has limitations, even data collected by clinical trials. For instance, administrative claims data usually lacks the granularity of lab test results, meanwhile clinical trials are sometime been criticized for a short follow-up period to observe long-term outcomes or adverse events. Conducting linkage (tokenization, when deterministic linkage is not feasible) across different data sources would be able to enrich data elements and to extend the longitudinal data with minimum interference with study subjects. There are several published studies provided insights into linking different data sources and assessing the validity of outcomes obtained from RWD. The results open a door to enrich a single source data and to judicate endpoints collected by clinical trial by conducting linkage across different databases. Furthermore, it demonstrated a chance of extending clinical trial follow-up by linking with RWD for certain endpoints.

</div>



----

<div id="speaker4" style="display: flex; flex-direction: column;">

<h3>Improving Prediction of Adolescent Suicide Attempts with Electronic Health Records by Leveraging External Data Sources; 
[<a href="../docs/slides/AM4-ShaneSacco.pdf">Slides</a>], 
[<a href="https://youtu.be/CAwX3cA3zkg" target="_blank">Recording</a>]
</h3>

<h4>Shane Sacco</h4>

<p>
<img class="imgfloat" src="../docs/shane.jpg"/>

Dr. Shane J Sacco is a Postdoctoral Research Associate in the Department of Statistics at the University of Connecticut and a member at the Center for Population Health at the University of Connecticut Health Center. He received his PhD in Health Promotion Science at the University of Connecticut, with his dissertation focusing upon applied methods to improve nonlinear interaction testing in the social sciences. His current research aims to improve suicide risk prediction using transfer-learning techniques, clinical decision-making pipelines, and feature and outcome engineering.

</p>


<h4>Abstract</h4>

Suicide among adolescents and young adults has risen in the US over the last decade and has driven mandates for risk identification methods such as risk algorithms using electronic health records. However, published risk algorithms heretofore only identify around half of attempts on average with 90% specificity. With this, efforts to improve algorithms are still critical. One potential method to improve existing algorithms is to transfer features important to risk that are not found in analyzed electronic health records by means of data fusion, a principle within transfer learning. In the present talk, I will discuss an established framework to generate additional features for prediction by matching patients with those found in external sources, as well as, case studies to exhibit how and what additional information may be leveraged to improve prediction of suicide attempts in adolescent populations.

</div>


----

<div id="speaker5" style="display: flex; flex-direction: column;">

<h3>Indirect Treatment Comparisons: When Are They Needed and How Do They Work? 
[<a href="../docs/slides/PM1-HaitaoChu.pdf">Slides</a>], 
[<a href="https://youtu.be/y1EzinNn8CY" target="_blank">Recording</a>]
</h3>

<h4>Haitao Chu</h4>

<p>
<img class="imgfloat" src="../docs/HaitaoChu.jfif"/>
Dr. Haitao Chu is a Senior Director in the Statistical Research and Data Science Center at Pfizer Inc. Before he joined Pfizer in April 2022, he was a tenured full Professor of Biostatistics in the University of Minnesota Twin Cities since 2017. He has published over 240 articles and is a Fellow of American Statistical Association. He currently serves as an Associate Editor for the Journal of the American Statistical Association and the American Journal of Epidemiology.
</p>


<h4>Abstract</h4>

In many markets, gaining approval by national reimbursement, pricing, or health technology assessment agencies is critical to the commercial success of a new product launch. In the absence of direct evidence from head-to-head RCTs, private and national payers often expect to see evidence from indirect treatment comparisons including Bucher’s method, network meta-analysis (NMA) or population adjusted indirect comparison (PAIC) to demonstrate the clinical value of the new technology. In this talk, I will provide an overview on indirect treatment comparisons focusing on when are they needed and how do they work? In addition, we will discuss the assumptions, advantages, and disadvantages of each approach. In practice, it is important to consider multiple approaches as sensitivity analyses and to provide totality of evidence as indirect treatment comparison is at high risk of bias no matter which approach is chosen. 

</div>

----

<div id="speaker6" style="display: flex; flex-direction: column;">

<h3>Disentangling the Clinical Complexity of Heterogeneous Diseases through Subphenotyping on Large Scale Electronic Health Records with Machine Learning; 
[<a href="../docs/slides/PM2-FeiWang.pdf">Slides</a>], 
[<a href="https://youtu.be/FkospzWfCrs" target="_blank">Recording</a>]
</h3>

<h4>Fei Wang</h4>

<p>
<img class="imgfloat" src="../docs/FeiWang.jpeg"/>
Fei Wang is currently an Associate Professor of Health Informatics in Department of Population Health Sciences, Weill Cornell Medicine, Cornell University. His major research interest is machine learning and its applications in health data science. He has published more than 300 papers in AI and medicine, which have received more than 23K citations Google Scholar. His H-index is 73. His papers have won 8 best paper awards at top international conferences on data mining and medical informatics. His team won the championship of the PTHrP results prediction challenge organized by the American Association of Clinical Chemistry in 2022, NIPS/Kaggle Challenge on Classification of Clinically Actionable Genetic Mutations in 2017 and Parkinson’s Progression Markers’ Initiative data challenge organized by Michael J. Fox Foundation in 2016. Dr. Wang is the recipient of the NSF CAREER Award in 2018, the inaugural research leadership award in IEEE International Conference on Health Informatics (ICHI) 2019. Dr. Wang is a Fellow of the American Medical Informatics Association (AMIA), a Fellow of the International Academy of Health Sciences and Informatics (IAHSI), a Fellow of the American College of Medical Informatics (ACMI), and a Distinguished Member of the Association for Computing Machinery (ACM). 
</p>

<h4>Abstract</h4>

Diseases such as COVID-19 are highly complex in patients’ clinical manifestations. Disentanglement of such clinical complexity into subpehnotypes can reveal the hidden patterns of the disease and inform stratified medicine. Electronic Health Records (EHRs) are important sources containing rich clinical information but there are many inherent challenges for analyzing them, such as sparsity, high-dimensionality and temporality. In this talk, taking COVID-19 as an example, I will introduce our research on deriving disease subphenotypes from large scale EHR repositories using machine learning approaches, point out the challenges and future research directions. 

</div>


----

<div id="speaker7" style="display: flex; flex-direction: column;">

<h3>Meta-regression Case Studies in Infectious Disease Epidemiology; 
[<a href="../docs/slides/PM3-JoshuaWarren.pdf">Slides</a>], 
[<a href="https://youtu.be/4k1Aw3ApRNU" target="_blank">Recording</a>]
</h3>

<h4>Joshua L. Warren</h4>

<p>
<img class="imgfloat" src="../docs/joshua.jpeg"/>
Joshua Warren is an Associate Professor in the Department of Biostatistics at the Yale School of Public Health. He received his Ph.D. in statistics from North Carolina State University in 2011. Dr. Warren’s research focuses on statistical methods in public health with an emphasis on environmental health problems. Much of his work involves introducing spatial and spatiotemporal models in the Bayesian setting to learn more about associations between environmental exposures, such as air pollution, and various health outcomes including preterm birth, low birth weight, and congenital anomalies. He also has interest in developing and applying spatiotemporal models in collaborative settings such as epidemiology, geography, nutrition, and glaucoma research. His theoretical and methodological interests include multiple topics in spatial/spatiotemporal modeling and Bayesian nonparameterics.
</p>

<h4>Abstract</h4>

Meta-analyses and meta-regressions are becomingly increasingly common in infectious disease epidemiology for interpolating important measures across different spatial locations and time points. However, the standard methods of analysis often need to be extended to accommodate unique features of the collected data and to more directly answer primary hypotheses posed by the research group. In this talk, I discuss two recent examples where new statistical methodology within the hierarchical Bayesian framework was developed to (i) estimate the burden of tuberculosis in incarcerated persons and (ii) quantify the efficacy and effectiveness of a vaccine.      

</div>